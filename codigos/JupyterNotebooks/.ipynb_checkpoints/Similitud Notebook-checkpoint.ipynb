{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similitud Notebook\n",
    "En este notebook podremos analizar con más facilidad la similitud entre las respuestas calificadas con mayor calificación con las de menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importo librerias\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hunspell import Hunspell\n",
    "\n",
    "h = Hunspell('es_MX', hunspell_data_dir = 'C:/Python/Lib/site-packages/dictionaries')\n",
    "spa_lex = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con esto evito que se impriman 'errores'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciar modelo Gensim\n",
    "Cristian Cardellino: Spanish Billion Words Corpus and Embeddings (March 2016), https://crscardellino.github.io/SBWCE/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(\"C:/Users/Drablaguna/Desktop/UNAM/SBW-vectors-300-min5.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalChar(x):\n",
    "    if x in [\",\",\".\",\":\",\";\",\"`\",\"'\",'\"',\"(\",\")\",\"-\",\"_\",\"~\",\"/\",\"?\",\"¿\",\"=\",\"[\",\"]\",\"\\n\",\"\\r\"]:\n",
    "        x = \"\"\n",
    "    return x\n",
    "def cleanString(x):\n",
    "    \"\"\"eliminar caracteres de puntuacion\"\"\"\n",
    "    s = map(evalChar, x)\n",
    "    s = \"\".join(list(s))\n",
    "    return s\n",
    "\n",
    "def start_dict():\n",
    "    \"\"\"inicializar el diccionario de resultados, para tener resultados diferentes por prueba\"\"\"\n",
    "    dic = {\n",
    "    'token_base': [],      # tokens originales\n",
    "    'token_toCompare': [], # token con el que se comparo\n",
    "    'similarity': [],      # valor de la similitud de ambos\n",
    "    'total_sim_mean': 0    # promedio similitud por frase\n",
    "    }\n",
    "    return dic\n",
    "\n",
    "def checkWord(word, hun_dic, original_sentence):\n",
    "    \"\"\"elegir la palabra correcta entre sus sugerencias\"\"\"\n",
    "    if not hun_dic.spell(word): # si la palabra NO se encuentra en el diccionario hunspell\n",
    "        n = 0\n",
    "        a = hun_dic.suggest(word)\n",
    "        print(\"=> \" + original_sentence)\n",
    "        for x in a:\n",
    "            print(str(n) + \": \" + x)\n",
    "            n+=1\n",
    "        # se puede ingresar la respuesta correcta con el id o escribiendola manualmente\n",
    "        correct_id_word = input(\"(\"+word+\") ID respuesta correcta o ingresa la palabra: \")\n",
    "        if correct_id_word.isdigit():\n",
    "            correct = a[int(correct_id_word)]\n",
    "        else:\n",
    "            correct = correct_id_word\n",
    "    else: # si la palabra se encuentra en el diccionario hunspell\n",
    "        correct = word\n",
    "    return correct.strip().lower()\n",
    "\n",
    "def checkSentence(s_string, hun_dic):\n",
    "    \"\"\"checar una oracion usando la funcion de escoger la palabra correcta\"\"\"\n",
    "    new_sentence = []\n",
    "    for token in s_string.split(\" \"): # se evaluara cada token si es una palabra existente o no\n",
    "        correct_word = checkWord(token, hun_dic, s_string)\n",
    "        if correct_word != \"\": # se agregara a la oracion nueva solo si es algo\n",
    "            new_sentence.append(correct_word)\n",
    "    #print(\"\\n\")\n",
    "    return \" \".join(new_sentence)\n",
    "        \n",
    "# s = \"porque sii mas que nada\"\n",
    "# s = checkSentence(s,h)\n",
    "# print(s)\n",
    "\n",
    "def print_graded_subsets(df_base, head):\n",
    "    \"\"\"Imprimir las dimensiones de los 4 subsets de una columna, de acuerdo a su evaluacion\"\"\"\n",
    "    df_three = df_base.loc[df_base[eval_col] == 3]\n",
    "    df_two   = df_base.loc[df_base[eval_col] == 2]\n",
    "    df_one   = df_base.loc[df_base[eval_col] == 1]\n",
    "    df_zero  = df_base.loc[df_base[eval_col] == 0]\n",
    "    print(\" === 3 === \")\n",
    "    print(df_three.head(head))\n",
    "    print(df_three.shape)\n",
    "    print(\"\\n\")\n",
    "    print(\" === 2 === \")\n",
    "    print(df_two.head(head))\n",
    "    print(df_two.shape)\n",
    "    print(\"\\n\")\n",
    "    print(\" === 1 === \")\n",
    "    print(df_one.head(head))\n",
    "    print(df_one.shape)\n",
    "    print(\"\\n\")\n",
    "    print(\" === 0 === \")\n",
    "    print(df_zero.head(head))\n",
    "    print(df_zero.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analize(base, comparer, method):\n",
    "    dic = start_dict()\n",
    "    \n",
    "    if method == \"gensim\":\n",
    "        base = base.split(\" \")\n",
    "        comparer = comparer.split(\" \")\n",
    "        \n",
    "    for token_base in base:\n",
    "        for token_toCompare in comparer:\n",
    "            \n",
    "            if method == \"spacy\":\n",
    "                simil = token_base.similarity(token_toCompare)\n",
    "                dic['token_base'].append(token_base.text)\n",
    "                dic['token_toCompare'].append(token_toCompare.text)\n",
    "                dic['similarity'].append(simil)\n",
    "            \n",
    "            if method == \"gensim\":\n",
    "                try:\n",
    "                    simil = model.wv.similarity(w1=token_base, w2=token_toCompare)\n",
    "                except KeyError:\n",
    "                    print(f\"---> Alguna de las siguientes palabras: ['{token_base}', '{token_toCompare}'] , no fue encontrada.\")\n",
    "                    simil = 0\n",
    "                dic['token_base'].append(token_base)\n",
    "                dic['token_toCompare'].append(token_toCompare)\n",
    "                dic['similarity'].append(simil)\n",
    "                \n",
    "    # genero el promedio de similitud que fue extraido de la sim de cada token con token\n",
    "    dic['total_sim_mean'] = np.mean(dic['similarity'])\n",
    "    return dic\n",
    "\n",
    "def quickize(master_row, slave_row, spell_check, method):\n",
    "    \"\"\"analizar rapido y mostrar similitud\"\"\"\n",
    "    \n",
    "    \"\"\" ========== H U N S P E L L ========== \"\"\"\n",
    "    if spell_check == True:\n",
    "        master_row = checkSentence(master_row,h)\n",
    "        slave_row = checkSentence(slave_row,h)\n",
    "\n",
    "    \"\"\" ============= S P A C Y ============= \"\"\"\n",
    "    if method == \"spacy\":\n",
    "        master_row = spa_lex(master_row)\n",
    "        slave_row = spa_lex(slave_row)\n",
    "        dic = analize(master_row, slave_row, method)\n",
    "    else:\n",
    "        \"\"\" ========== G E N S I M ========== \"\"\"\n",
    "        dic = analize(master_row, slave_row, method)\n",
    "    \n",
    "    return dic\n",
    "\n",
    "def print_zip(dic):\n",
    "    \"\"\"imprimir las palabras que se compararon y sus similitudes\"\"\"\n",
    "    print(list(zip(dic['token_base'], dic['token_toCompare'], dic['similarity'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Drablaguna/Desktop/UNAM/EvaluacionCognitiva/Bases de datos/Secundaria/SECUNDARIA_TODO.csv\")\n",
    "\n",
    "# df = pd.read_csv(\"C:/Users/Drablaguna/Desktop/UNAM/EvaluacionCognitiva/cuenta_de_palabras/WORDCOUNT_SECUNDARIA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECU TODO CLEAN ================================================================\n",
    "ans_col = \"explica_lo_que_quiere_decir_mi_hermanito_es_una_pelota_de_gritos\"\n",
    "eval_col = \"a5\"\n",
    "\n",
    "# WORDCOUNT SECUNDARIA ===========================================================\n",
    "# ans_col = \"explica_lo_que_quiere_decir_mi_hermanito_es_una_pelota_de_gritos_clean_ans\"\n",
    "# eval_col = \"explica_lo_que_quiere_decir_mi_hermanito_es_una_pelota_de_gritos_eval\"\n",
    "\n",
    "# obtengo los valores de respuestas limpias y sus evaluaciones en un dataframe\n",
    "df_base = df[[ans_col, eval_col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes evaluados a  3, 2, 1 y 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_graded_subsets(df_base, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_df_res(master_row, df_slave, ans_col):\n",
    "    \"\"\"evaluar 1 respuesta de 3 con master rows definidas\"\"\"\n",
    "    counter = 1\n",
    "    results = []\n",
    "    master_row = cleanString(master_row)\n",
    "    #print(\"============================== \"+master_row.upper()+\" ==============================\")\n",
    "    for line in df_slave[ans_col]:\n",
    "        slave_row = cleanString(line)\n",
    "        if slave_row != \"\": # para evitar evaluaciones donde la fila este vacia\n",
    "            r = quickize(master_row, slave_row, False, \"spacy\")\n",
    "            results.append(r['total_sim_mean'])\n",
    "            # print(str(r['total_sim_mean'])) # SIMILITUD POR ORACION\n",
    "            counter+=1\n",
    "    return results\n",
    "\n",
    "def quickPrint(df, ans_col, eval_col, n1, n2):\n",
    "    df_base  = df[[ans_col, eval_col]]\n",
    "    final_results = []\n",
    "    \n",
    "    df_three = df_base.loc[df_base[eval_col] == 3]\n",
    "    df_two   = df_base.loc[df_base[eval_col] == 2]\n",
    "    df_one   = df_base.loc[df_base[eval_col] == 1]\n",
    "    df_zero  = df_base.loc[df_base[eval_col] == 0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\" ======================= M A S T E R  R O W S ======================= \"\"\"\n",
    "    \n",
    "    #three_ans = \"por que hace mucho ruido\"\n",
    "    three_ans = \"porque grita mucho\"\n",
    "    \n",
    "    \"\"\" ==================================================================== \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 3 con 3\n",
    "    if n1 == 3 and n2 == 3:\n",
    "        final_results = print_df_res(three_ans, df_three, ans_col)\n",
    "        \n",
    "    # 3 con 2\n",
    "    if n1 == 3 and n2 == 2:\n",
    "        final_results = print_df_res(three_ans, df_two, ans_col)\n",
    "        \n",
    "    # 3 con 1\n",
    "    if n1 == 3 and n2 == 1:\n",
    "        final_results = print_df_res(three_ans, df_one, ans_col)\n",
    "        \n",
    "    # 3 con 0\n",
    "    if n1 == 3 and n2 == 0:\n",
    "        final_results = print_df_res(three_ans, df_zero, ans_col)\n",
    "    \n",
    "    \n",
    "    # 2 con 2\n",
    "    if n1 == 2 and n2 == 2:\n",
    "        final_results = print_df_res(three_ans, df_two, ans_col)\n",
    "        \n",
    "    # 2 con 1\n",
    "    if n1 == 2 and n2 == 1:\n",
    "        final_results = print_df_res(three_ans, df_one, ans_col)\n",
    "        \n",
    "    # 2 con 0\n",
    "    if n1 == 2 and n2 == 0:\n",
    "        final_results = print_df_res(three_ans, df_zero, ans_col)\n",
    "        \n",
    "    \n",
    "    # 1 con 1\n",
    "    if n1 == 1 and n2 == 1:\n",
    "        final_results = print_df_res(three_ans, df_one, ans_col)\n",
    "        \n",
    "    # 1 con 0\n",
    "    if n1 == 1 and n2 == 0:\n",
    "        final_results = print_df_res(three_ans, df_zero, ans_col)\n",
    "        \n",
    "    \n",
    "    # 0 con 0\n",
    "    if n1 == 0 and n2 == 0:\n",
    "        final_results = print_df_res(three_ans, df_zero, ans_col)\n",
    "        \n",
    "    \n",
    "    # Imprimir resultados\n",
    "    pprint(list(enumerate(final_results, 1)))\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.7288816372553507),\n",
      " (2, 0.6649290492965115),\n",
      " (3, 0.6315362),\n",
      " (4, 0.652271835009257),\n",
      " (5, 0.2991424),\n",
      " (6, 0.7424302061398824),\n",
      " (7, 0.49095547),\n",
      " (8, 0.6985541993663424),\n",
      " (9, 0.6450944562753042),\n",
      " (10, 0.6178799240539471),\n",
      " (11, 0.6806993219587538),\n",
      " (12, 0.5420271),\n",
      " (13, 0.6517095),\n",
      " (14, 0.54654944),\n",
      " (15, 0.5531775802373886),\n",
      " (16, 0.6332104847286687),\n",
      " (17, 0.6851957477629185),\n",
      " (18, 0.7627253598637052),\n",
      " (19, 0.4831347326437632),\n",
      " (20, 0.46953237),\n",
      " (21, 0.7390085856119791),\n",
      " (22, 0.7627253598637052),\n",
      " (23, 0.6977026694350772),\n",
      " (24, 0.7129826545715332),\n",
      " (25, 0.6756404),\n",
      " (26, 0.7390085856119791),\n",
      " (27, 0.7361317873001099),\n",
      " (28, 0.674493400255839),\n",
      " (29, 0.5597802),\n",
      " (30, 0.7036789),\n",
      " (31, 0.68687147),\n",
      " (32, 0.4860074669122696),\n",
      " (33, 0.5768997371196747),\n",
      " (34, 0.7065931558609009),\n",
      " (35, 0.528762956460317),\n",
      " (36, 0.65619165),\n",
      " (37, 0.68239415),\n",
      " (38, 0.7230426708857218),\n",
      " (39, 0.7327465936541557),\n",
      " (40, 0.58972836),\n",
      " (41, 0.6711090554793676),\n",
      " (42, 0.08603561),\n",
      " (43, 0.6916011323531469),\n",
      " (44, 0.6924364045262337),\n",
      " (45, 0.7059453494018979),\n",
      " (46, 0.6972617297260849),\n",
      " (47, 0.6737633620699247),\n",
      " (48, 0.6595115),\n",
      " (49, 0.664345424799692),\n",
      " (50, 0.7016486277182897),\n",
      " (51, 0.761839767297109),\n",
      " (52, 0.3049387),\n",
      " (53, 0.7627253598637052),\n",
      " (54, 0.6833871006965637),\n",
      " (55, 0.733519658446312),\n",
      " (56, 0.6997639),\n",
      " (57, 0.7198840436481294),\n",
      " (58, 0.7869306670294868),\n",
      " (59, 0.4046739),\n",
      " (60, 0.7627253598637052),\n",
      " (61, 0.6356438),\n",
      " (62, 0.66294235),\n",
      " (63, 0.7368043184280395),\n",
      " (64, 0.5000765522321066),\n",
      " (65, 0.7294803261756897),\n",
      " (66, 0.7230426708857218),\n",
      " (67, 0.6335347),\n",
      " (68, 0.5962741),\n",
      " (69, 0.4967115471760432),\n",
      " (70, 0.687706313751362),\n",
      " (71, 0.44989333),\n",
      " (72, 0.49229795),\n",
      " (73, 0.5770916028155221),\n",
      " (74, 0.5828808140423563),\n",
      " (75, 0.7098751719351168),\n",
      " (76, 0.7270344538348061),\n",
      " (77, 0.57853293),\n",
      " (78, 0.6695363968610764),\n",
      " (79, 0.6873074372609457),\n",
      " (80, 0.60218704),\n",
      " (81, 0.7320343355337778),\n",
      " (82, 0.7368043184280395),\n",
      " (83, 0.23439699163039526),\n",
      " (84, 0.7335725873708725),\n",
      " (85, 0.7390085856119791),\n",
      " (86, 0.7136824478705724),\n",
      " (87, 0.6352862),\n",
      " (88, 0.6714604794979095),\n",
      " (89, 0.6885607),\n",
      " (90, 0.7869306670294868),\n",
      " (91, 0.6516198379298052),\n",
      " (92, 0.6737495),\n",
      " (93, 0.680678931651292),\n",
      " (94, 0.7110845),\n",
      " (95, 0.6489370009965367),\n",
      " (96, 0.7627253598637052),\n",
      " (97, 0.7869306670294868),\n",
      " (98, 0.7189297278722128),\n",
      " (99, 0.7266404264503055),\n",
      " (100, 0.7181512653827667),\n",
      " (101, 0.66805834),\n",
      " (102, 0.7509677708148956),\n",
      " (103, 0.7267359),\n",
      " (104, 0.59699607),\n",
      " (105, 0.7627253598637052),\n",
      " (106, 0.7264225043001629),\n",
      " (107, 0.7355448504288992),\n",
      " (108, 0.62514985),\n",
      " (109, 0.6381203631560007),\n",
      " (110, 0.6692784428596497),\n",
      " (111, 0.63914174),\n",
      " (112, 0.64785373),\n",
      " (113, 0.7355448504288992),\n",
      " (114, 0.7280430912971496),\n",
      " (115, 0.6757778459125094),\n",
      " (116, 0.7230426708857218),\n",
      " (117, 0.6180336008469264),\n",
      " (118, 0.6908134420712789),\n",
      " (119, 0.6157261803746223),\n",
      " (120, 0.7266404264503055),\n",
      " (121, 0.67602485),\n",
      " (122, 0.7044608443975449),\n",
      " (123, 0.7098081),\n",
      " (124, 0.6894939243793488),\n",
      " (125, 0.7554773622088962),\n",
      " (126, 0.49167237),\n",
      " (127, 0.7355448504288992),\n",
      " (128, 0.7050661),\n",
      " (129, 0.67118233),\n",
      " (130, 0.6676095006140795),\n",
      " (131, 0.61618316),\n",
      " (132, 0.7627253598637052),\n",
      " (133, 0.7627253598637052),\n",
      " (134, 0.6843633),\n",
      " (135, 0.6921448523089999),\n",
      " (136, 0.6862108442518446),\n",
      " (137, 0.7264225043001629),\n",
      " (138, 0.7364182343085607),\n",
      " (139, 0.6167761275061855),\n",
      " (140, 0.6719211806853612),\n",
      " (141, 0.6948580486433846),\n",
      " (142, 0.7554773622088962),\n",
      " (143, 0.53931165),\n",
      " (144, 0.6927012),\n",
      " (145, 0.5889933121701082),\n",
      " (146, 0.6072572438667218),\n",
      " (147, 0.7508457336160872),\n",
      " (148, 0.7627253598637052),\n",
      " (149, 0.6636318),\n",
      " (150, 0.7381400068600973),\n",
      " (151, 0.7627253598637052),\n",
      " (152, 0.7352681994438172),\n",
      " (153, 0.4412476),\n",
      " (154, 0.7038171862562498),\n",
      " (155, 0.7627253598637052),\n",
      " (156, 0.7390085856119791),\n",
      " (157, 0.7627253598637052),\n",
      " (158, 0.72583985),\n",
      " (159, 0.6889548415229434),\n",
      " (160, 0.6910769095023473),\n",
      " (161, 0.7280430912971496),\n",
      " (162, 0.5638827277081353),\n",
      " (163, 0.6792920418083668),\n",
      " (164, 0.49816015),\n",
      " (165, 0.7627253598637052),\n",
      " (166, 0.6630113045374553),\n",
      " (167, 0.6789989272753397),\n",
      " (168, 0.69291645),\n",
      " (169, 0.5708125),\n",
      " (170, 0.7568851775593228),\n",
      " (171, 0.7089274128278097),\n",
      " (172, 0.5417110550971258),\n",
      " (173, 0.7089274128278097),\n",
      " (174, 0.7627253598637052),\n",
      " (175, 0.7048760533332825),\n",
      " (176, 0.6767571608225504),\n",
      " (177, 0.717003247804112),\n",
      " (178, 0.5533653423190117),\n",
      " (179, 0.6382722),\n",
      " (180, 0.6314247),\n",
      " (181, 0.7126792023579279),\n",
      " (182, 0.7189297278722128),\n",
      " (183, 0.72249806),\n",
      " (184, 0.6321584),\n",
      " (185, 0.5511131),\n",
      " (186, 0.7368043184280395),\n",
      " (187, 0.58992165),\n",
      " (188, 0.7230426708857218),\n",
      " (189, 0.547864),\n",
      " (190, 0.6924505),\n",
      " (191, 0.66881204),\n",
      " (192, 0.7548729015721215),\n",
      " (193, 0.7211508064559011),\n",
      " (194, 0.60164),\n",
      " (195, 0.7362522525446755),\n",
      " (196, 0.69172),\n",
      " (197, 0.7548729015721215),\n",
      " (198, 0.0),\n",
      " (199, 0.5274351),\n",
      " (200, 0.6310052),\n",
      " (201, 0.7627253598637052),\n",
      " (202, 0.7230426708857218),\n",
      " (203, 0.67207897),\n",
      " (204, 0.6264527986447016),\n",
      " (205, 0.7368043184280395),\n",
      " (206, 0.6016743),\n",
      " (207, 0.6957105954488119),\n",
      " (208, 0.617313876748085),\n",
      " (209, 0.586858069896698),\n",
      " (210, 0.5892874),\n",
      " (211, 0.1427444),\n",
      " (212, 0.54543835),\n",
      " (213, 0.7554773622088962),\n",
      " (214, 0.7418047388394674),\n",
      " (215, 0.5730443856655023),\n",
      " (216, 0.7212941972982316),\n",
      " (217, 0.7125277306352343),\n",
      " (218, 0.7073357055584589),\n",
      " (219, 0.3339291314284007),\n",
      " (220, 0.7361317873001099),\n",
      " (221, 0.691866027812163),\n",
      " (222, 0.673698),\n",
      " (223, 0.41669464),\n",
      " (224, 0.7390085856119791),\n",
      " (225, 0.6078388412793477),\n",
      " (226, 0.67480326),\n",
      " (227, 0.7264225043001629),\n",
      " (228, 0.7266404264503055),\n",
      " (229, 0.7070244586828983),\n",
      " (230, 0.5641823447111881),\n",
      " (231, 0.6421848071946038),\n",
      " (232, 0.51379514),\n",
      " (233, 0.7390085856119791),\n",
      " (234, 0.64203006),\n",
      " (235, 0.653429144904727),\n",
      " (236, 0.5980295),\n",
      " (237, 0.5531775802373886),\n",
      " (238, 0.6830292065938314),\n",
      " (239, 0.5725090288453631),\n",
      " (240, 0.7251304229100545),\n",
      " (241, 0.737455940246582),\n",
      " (242, 0.7186938722928365),\n",
      " (243, 0.6808937122424443),\n",
      " (244, 0.7161262227429284),\n",
      " (245, 0.693849558631579),\n",
      " (246, 0.7264225043001629),\n",
      " (247, 0.501229760547479),\n",
      " (248, 0.723119896082651),\n",
      " (249, 0.595143636999031),\n",
      " (250, 0.705948),\n",
      " (251, 0.7869306670294868),\n",
      " (252, 0.725019),\n",
      " (253, 0.6904928473134836),\n",
      " (254, 0.7203734275840578),\n",
      " (255, 0.64894485),\n",
      " (256, 0.7075181893813305),\n",
      " (257, 0.68272156),\n",
      " (258, 0.761839767297109),\n",
      " (259, 0.5253336),\n",
      " (260, 0.7113687753677368),\n",
      " (261, 0.7509677708148956),\n",
      " (262, 0.5435865),\n",
      " (263, 0.761839767297109),\n",
      " (264, 0.5772604692313407),\n",
      " (265, 0.5832691),\n",
      " (266, 0.7627253598637052),\n",
      " (267, 0.7041535059611003),\n",
      " (268, 0.66915065),\n",
      " (269, 0.6927012),\n",
      " (270, 0.6394110146241311),\n",
      " (271, 0.51379514),\n",
      " (272, 0.7280430912971496),\n",
      " (273, 0.7280430912971496),\n",
      " (274, 0.7243590099470956),\n",
      " (275, 0.5425637656201919),\n",
      " (276, 0.7627253598637052),\n",
      " (277, 0.6747524),\n",
      " (278, 0.6851191079175031),\n",
      " (279, 0.7230426708857218),\n",
      " (280, 0.7230426708857218),\n",
      " (281, 0.5686037412711552),\n",
      " (282, 0.7092331),\n",
      " (283, 0.45801815),\n",
      " (284, 0.6405043),\n",
      " (285, 0.6971397012472152),\n",
      " (286, 0.6048422),\n",
      " (287, 0.7230426708857218),\n",
      " (288, 0.4988337482015292),\n",
      " (289, 0.7368043184280395),\n",
      " (290, 0.6366735845804214),\n",
      " (291, 0.41548097),\n",
      " (292, 0.5894769),\n",
      " (293, 0.7481359283129374),\n",
      " (294, 0.6593341181675593),\n",
      " (295, 0.7230426708857218),\n",
      " (296, 0.7708796163400015),\n",
      " (297, 0.68924904),\n",
      " (298, 0.6511442),\n",
      " (299, 0.68052536),\n",
      " (300, 0.7065760175387065),\n",
      " (301, 0.626717725679988),\n",
      " (302, 0.6435005),\n",
      " (303, 0.6993221326006783),\n",
      " (304, 0.7627253598637052),\n",
      " (305, 0.71424353),\n",
      " (306, 0.6843633),\n",
      " (307, 0.6094833537936211),\n",
      " (308, 0.5871244),\n",
      " (309, 0.7189297278722128),\n",
      " (310, 0.51112676),\n",
      " (311, 0.72583985),\n",
      " (312, 0.6483751),\n",
      " (313, 0.7289571762084961),\n",
      " (314, 0.7627253598637052),\n",
      " (315, 0.67543584),\n",
      " (316, 0.7230426708857218),\n",
      " (317, 0.6158218656977018),\n",
      " (318, 0.7368043184280395),\n",
      " (319, 0.6599661426411735),\n",
      " (320, 0.6619347),\n",
      " (321, 0.42708182),\n",
      " (322, 0.7200136113734472),\n",
      " (323, 0.68716115),\n",
      " (324, 0.6545932913819948),\n",
      " (325, 0.7230426708857218),\n",
      " (326, 0.5852676559062231),\n",
      " (327, 0.7003813343388694),\n",
      " (328, 0.7571096370617548),\n",
      " (329, 0.6916147456282661),\n",
      " (330, 0.6927012),\n",
      " (331, 0.5833085308472316),\n",
      " (332, 0.7207878887653351),\n",
      " (333, 0.6536848),\n",
      " (334, 0.42949536),\n",
      " (335, 0.36249512),\n",
      " (336, 0.6742291546919766),\n",
      " (337, 0.6606347),\n",
      " (338, 0.69416696),\n",
      " (339, 0.7627253598637052),\n",
      " (340, 0.59112376),\n",
      " (341, 0.7089274128278097),\n",
      " (342, 0.7627253598637052),\n",
      " (343, 0.7008293221394221),\n",
      " (344, 0.64141804),\n",
      " (345, 0.6873313188552856),\n",
      " (346, 0.5592603514591853),\n",
      " (347, 0.7644657343626022),\n",
      " (348, 0.7627253598637052),\n",
      " (349, 0.7091188563240899),\n",
      " (350, 0.64434034),\n",
      " (351, 0.6430727),\n",
      " (352, 0.6077356884876887),\n",
      " (353, 0.6990229189395905),\n",
      " (354, 0.6687524),\n",
      " (355, 0.6911315595110258),\n",
      " (356, 0.7230426708857218),\n",
      " (357, 0.7230426708857218),\n",
      " (358, 0.64592469856143),\n",
      " (359, 0.7166851347401029),\n",
      " (360, 0.49816015),\n",
      " (361, 0.6267763177553812),\n",
      " (362, 0.72583985),\n",
      " (363, 0.5130400740438037),\n",
      " (364, 0.6489262362321218),\n",
      " (365, 0.690390564146496),\n",
      " (366, 0.6588555133342743),\n",
      " (367, 0.5686093333768107),\n",
      " (368, 0.6903727451960245),\n",
      " (369, 0.682686),\n",
      " (370, 0.7184989551703135),\n",
      " (371, 0.6402704815069834),\n",
      " (372, 0.6358361513841719),\n",
      " (373, 0.6758855643371741),\n",
      " (374, 0.49816015),\n",
      " (375, 0.7043238878250122),\n",
      " (376, 0.6970924359780771),\n",
      " (377, 0.6542901277542115),\n",
      " (378, 0.5886681543456184),\n",
      " (379, 0.67890763),\n",
      " (380, 0.7113687753677368),\n",
      " (381, 0.59182876),\n",
      " (382, 0.7126792023579279),\n",
      " (383, 0.7230426708857218),\n",
      " (384, 0.71598315),\n",
      " (385, 0.6993898327151934),\n",
      " (386, 0.6849393745263418),\n",
      " (387, 0.70033383),\n",
      " (388, 0.6367387591846405),\n",
      " (389, 0.24873225),\n",
      " (390, 0.7131726074786413),\n",
      " (391, 0.72583985),\n",
      " (392, 0.69035286),\n",
      " (393, 0.7361317873001099),\n",
      " (394, 0.6432618),\n",
      " (395, 0.7627253598637052),\n",
      " (396, 0.588441),\n",
      " (397, 0.6476535714334912)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7288816372553507,\n",
       " 0.6649290492965115,\n",
       " 0.6315362,\n",
       " 0.652271835009257,\n",
       " 0.2991424,\n",
       " 0.7424302061398824,\n",
       " 0.49095547,\n",
       " 0.6985541993663424,\n",
       " 0.6450944562753042,\n",
       " 0.6178799240539471,\n",
       " 0.6806993219587538,\n",
       " 0.5420271,\n",
       " 0.6517095,\n",
       " 0.54654944,\n",
       " 0.5531775802373886,\n",
       " 0.6332104847286687,\n",
       " 0.6851957477629185,\n",
       " 0.7627253598637052,\n",
       " 0.4831347326437632,\n",
       " 0.46953237,\n",
       " 0.7390085856119791,\n",
       " 0.7627253598637052,\n",
       " 0.6977026694350772,\n",
       " 0.7129826545715332,\n",
       " 0.6756404,\n",
       " 0.7390085856119791,\n",
       " 0.7361317873001099,\n",
       " 0.674493400255839,\n",
       " 0.5597802,\n",
       " 0.7036789,\n",
       " 0.68687147,\n",
       " 0.4860074669122696,\n",
       " 0.5768997371196747,\n",
       " 0.7065931558609009,\n",
       " 0.528762956460317,\n",
       " 0.65619165,\n",
       " 0.68239415,\n",
       " 0.7230426708857218,\n",
       " 0.7327465936541557,\n",
       " 0.58972836,\n",
       " 0.6711090554793676,\n",
       " 0.08603561,\n",
       " 0.6916011323531469,\n",
       " 0.6924364045262337,\n",
       " 0.7059453494018979,\n",
       " 0.6972617297260849,\n",
       " 0.6737633620699247,\n",
       " 0.6595115,\n",
       " 0.664345424799692,\n",
       " 0.7016486277182897,\n",
       " 0.761839767297109,\n",
       " 0.3049387,\n",
       " 0.7627253598637052,\n",
       " 0.6833871006965637,\n",
       " 0.733519658446312,\n",
       " 0.6997639,\n",
       " 0.7198840436481294,\n",
       " 0.7869306670294868,\n",
       " 0.4046739,\n",
       " 0.7627253598637052,\n",
       " 0.6356438,\n",
       " 0.66294235,\n",
       " 0.7368043184280395,\n",
       " 0.5000765522321066,\n",
       " 0.7294803261756897,\n",
       " 0.7230426708857218,\n",
       " 0.6335347,\n",
       " 0.5962741,\n",
       " 0.4967115471760432,\n",
       " 0.687706313751362,\n",
       " 0.44989333,\n",
       " 0.49229795,\n",
       " 0.5770916028155221,\n",
       " 0.5828808140423563,\n",
       " 0.7098751719351168,\n",
       " 0.7270344538348061,\n",
       " 0.57853293,\n",
       " 0.6695363968610764,\n",
       " 0.6873074372609457,\n",
       " 0.60218704,\n",
       " 0.7320343355337778,\n",
       " 0.7368043184280395,\n",
       " 0.23439699163039526,\n",
       " 0.7335725873708725,\n",
       " 0.7390085856119791,\n",
       " 0.7136824478705724,\n",
       " 0.6352862,\n",
       " 0.6714604794979095,\n",
       " 0.6885607,\n",
       " 0.7869306670294868,\n",
       " 0.6516198379298052,\n",
       " 0.6737495,\n",
       " 0.680678931651292,\n",
       " 0.7110845,\n",
       " 0.6489370009965367,\n",
       " 0.7627253598637052,\n",
       " 0.7869306670294868,\n",
       " 0.7189297278722128,\n",
       " 0.7266404264503055,\n",
       " 0.7181512653827667,\n",
       " 0.66805834,\n",
       " 0.7509677708148956,\n",
       " 0.7267359,\n",
       " 0.59699607,\n",
       " 0.7627253598637052,\n",
       " 0.7264225043001629,\n",
       " 0.7355448504288992,\n",
       " 0.62514985,\n",
       " 0.6381203631560007,\n",
       " 0.6692784428596497,\n",
       " 0.63914174,\n",
       " 0.64785373,\n",
       " 0.7355448504288992,\n",
       " 0.7280430912971496,\n",
       " 0.6757778459125094,\n",
       " 0.7230426708857218,\n",
       " 0.6180336008469264,\n",
       " 0.6908134420712789,\n",
       " 0.6157261803746223,\n",
       " 0.7266404264503055,\n",
       " 0.67602485,\n",
       " 0.7044608443975449,\n",
       " 0.7098081,\n",
       " 0.6894939243793488,\n",
       " 0.7554773622088962,\n",
       " 0.49167237,\n",
       " 0.7355448504288992,\n",
       " 0.7050661,\n",
       " 0.67118233,\n",
       " 0.6676095006140795,\n",
       " 0.61618316,\n",
       " 0.7627253598637052,\n",
       " 0.7627253598637052,\n",
       " 0.6843633,\n",
       " 0.6921448523089999,\n",
       " 0.6862108442518446,\n",
       " 0.7264225043001629,\n",
       " 0.7364182343085607,\n",
       " 0.6167761275061855,\n",
       " 0.6719211806853612,\n",
       " 0.6948580486433846,\n",
       " 0.7554773622088962,\n",
       " 0.53931165,\n",
       " 0.6927012,\n",
       " 0.5889933121701082,\n",
       " 0.6072572438667218,\n",
       " 0.7508457336160872,\n",
       " 0.7627253598637052,\n",
       " 0.6636318,\n",
       " 0.7381400068600973,\n",
       " 0.7627253598637052,\n",
       " 0.7352681994438172,\n",
       " 0.4412476,\n",
       " 0.7038171862562498,\n",
       " 0.7627253598637052,\n",
       " 0.7390085856119791,\n",
       " 0.7627253598637052,\n",
       " 0.72583985,\n",
       " 0.6889548415229434,\n",
       " 0.6910769095023473,\n",
       " 0.7280430912971496,\n",
       " 0.5638827277081353,\n",
       " 0.6792920418083668,\n",
       " 0.49816015,\n",
       " 0.7627253598637052,\n",
       " 0.6630113045374553,\n",
       " 0.6789989272753397,\n",
       " 0.69291645,\n",
       " 0.5708125,\n",
       " 0.7568851775593228,\n",
       " 0.7089274128278097,\n",
       " 0.5417110550971258,\n",
       " 0.7089274128278097,\n",
       " 0.7627253598637052,\n",
       " 0.7048760533332825,\n",
       " 0.6767571608225504,\n",
       " 0.717003247804112,\n",
       " 0.5533653423190117,\n",
       " 0.6382722,\n",
       " 0.6314247,\n",
       " 0.7126792023579279,\n",
       " 0.7189297278722128,\n",
       " 0.72249806,\n",
       " 0.6321584,\n",
       " 0.5511131,\n",
       " 0.7368043184280395,\n",
       " 0.58992165,\n",
       " 0.7230426708857218,\n",
       " 0.547864,\n",
       " 0.6924505,\n",
       " 0.66881204,\n",
       " 0.7548729015721215,\n",
       " 0.7211508064559011,\n",
       " 0.60164,\n",
       " 0.7362522525446755,\n",
       " 0.69172,\n",
       " 0.7548729015721215,\n",
       " 0.0,\n",
       " 0.5274351,\n",
       " 0.6310052,\n",
       " 0.7627253598637052,\n",
       " 0.7230426708857218,\n",
       " 0.67207897,\n",
       " 0.6264527986447016,\n",
       " 0.7368043184280395,\n",
       " 0.6016743,\n",
       " 0.6957105954488119,\n",
       " 0.617313876748085,\n",
       " 0.586858069896698,\n",
       " 0.5892874,\n",
       " 0.1427444,\n",
       " 0.54543835,\n",
       " 0.7554773622088962,\n",
       " 0.7418047388394674,\n",
       " 0.5730443856655023,\n",
       " 0.7212941972982316,\n",
       " 0.7125277306352343,\n",
       " 0.7073357055584589,\n",
       " 0.3339291314284007,\n",
       " 0.7361317873001099,\n",
       " 0.691866027812163,\n",
       " 0.673698,\n",
       " 0.41669464,\n",
       " 0.7390085856119791,\n",
       " 0.6078388412793477,\n",
       " 0.67480326,\n",
       " 0.7264225043001629,\n",
       " 0.7266404264503055,\n",
       " 0.7070244586828983,\n",
       " 0.5641823447111881,\n",
       " 0.6421848071946038,\n",
       " 0.51379514,\n",
       " 0.7390085856119791,\n",
       " 0.64203006,\n",
       " 0.653429144904727,\n",
       " 0.5980295,\n",
       " 0.5531775802373886,\n",
       " 0.6830292065938314,\n",
       " 0.5725090288453631,\n",
       " 0.7251304229100545,\n",
       " 0.737455940246582,\n",
       " 0.7186938722928365,\n",
       " 0.6808937122424443,\n",
       " 0.7161262227429284,\n",
       " 0.693849558631579,\n",
       " 0.7264225043001629,\n",
       " 0.501229760547479,\n",
       " 0.723119896082651,\n",
       " 0.595143636999031,\n",
       " 0.705948,\n",
       " 0.7869306670294868,\n",
       " 0.725019,\n",
       " 0.6904928473134836,\n",
       " 0.7203734275840578,\n",
       " 0.64894485,\n",
       " 0.7075181893813305,\n",
       " 0.68272156,\n",
       " 0.761839767297109,\n",
       " 0.5253336,\n",
       " 0.7113687753677368,\n",
       " 0.7509677708148956,\n",
       " 0.5435865,\n",
       " 0.761839767297109,\n",
       " 0.5772604692313407,\n",
       " 0.5832691,\n",
       " 0.7627253598637052,\n",
       " 0.7041535059611003,\n",
       " 0.66915065,\n",
       " 0.6927012,\n",
       " 0.6394110146241311,\n",
       " 0.51379514,\n",
       " 0.7280430912971496,\n",
       " 0.7280430912971496,\n",
       " 0.7243590099470956,\n",
       " 0.5425637656201919,\n",
       " 0.7627253598637052,\n",
       " 0.6747524,\n",
       " 0.6851191079175031,\n",
       " 0.7230426708857218,\n",
       " 0.7230426708857218,\n",
       " 0.5686037412711552,\n",
       " 0.7092331,\n",
       " 0.45801815,\n",
       " 0.6405043,\n",
       " 0.6971397012472152,\n",
       " 0.6048422,\n",
       " 0.7230426708857218,\n",
       " 0.4988337482015292,\n",
       " 0.7368043184280395,\n",
       " 0.6366735845804214,\n",
       " 0.41548097,\n",
       " 0.5894769,\n",
       " 0.7481359283129374,\n",
       " 0.6593341181675593,\n",
       " 0.7230426708857218,\n",
       " 0.7708796163400015,\n",
       " 0.68924904,\n",
       " 0.6511442,\n",
       " 0.68052536,\n",
       " 0.7065760175387065,\n",
       " 0.626717725679988,\n",
       " 0.6435005,\n",
       " 0.6993221326006783,\n",
       " 0.7627253598637052,\n",
       " 0.71424353,\n",
       " 0.6843633,\n",
       " 0.6094833537936211,\n",
       " 0.5871244,\n",
       " 0.7189297278722128,\n",
       " 0.51112676,\n",
       " 0.72583985,\n",
       " 0.6483751,\n",
       " 0.7289571762084961,\n",
       " 0.7627253598637052,\n",
       " 0.67543584,\n",
       " 0.7230426708857218,\n",
       " 0.6158218656977018,\n",
       " 0.7368043184280395,\n",
       " 0.6599661426411735,\n",
       " 0.6619347,\n",
       " 0.42708182,\n",
       " 0.7200136113734472,\n",
       " 0.68716115,\n",
       " 0.6545932913819948,\n",
       " 0.7230426708857218,\n",
       " 0.5852676559062231,\n",
       " 0.7003813343388694,\n",
       " 0.7571096370617548,\n",
       " 0.6916147456282661,\n",
       " 0.6927012,\n",
       " 0.5833085308472316,\n",
       " 0.7207878887653351,\n",
       " 0.6536848,\n",
       " 0.42949536,\n",
       " 0.36249512,\n",
       " 0.6742291546919766,\n",
       " 0.6606347,\n",
       " 0.69416696,\n",
       " 0.7627253598637052,\n",
       " 0.59112376,\n",
       " 0.7089274128278097,\n",
       " 0.7627253598637052,\n",
       " 0.7008293221394221,\n",
       " 0.64141804,\n",
       " 0.6873313188552856,\n",
       " 0.5592603514591853,\n",
       " 0.7644657343626022,\n",
       " 0.7627253598637052,\n",
       " 0.7091188563240899,\n",
       " 0.64434034,\n",
       " 0.6430727,\n",
       " 0.6077356884876887,\n",
       " 0.6990229189395905,\n",
       " 0.6687524,\n",
       " 0.6911315595110258,\n",
       " 0.7230426708857218,\n",
       " 0.7230426708857218,\n",
       " 0.64592469856143,\n",
       " 0.7166851347401029,\n",
       " 0.49816015,\n",
       " 0.6267763177553812,\n",
       " 0.72583985,\n",
       " 0.5130400740438037,\n",
       " 0.6489262362321218,\n",
       " 0.690390564146496,\n",
       " 0.6588555133342743,\n",
       " 0.5686093333768107,\n",
       " 0.6903727451960245,\n",
       " 0.682686,\n",
       " 0.7184989551703135,\n",
       " 0.6402704815069834,\n",
       " 0.6358361513841719,\n",
       " 0.6758855643371741,\n",
       " 0.49816015,\n",
       " 0.7043238878250122,\n",
       " 0.6970924359780771,\n",
       " 0.6542901277542115,\n",
       " 0.5886681543456184,\n",
       " 0.67890763,\n",
       " 0.7113687753677368,\n",
       " 0.59182876,\n",
       " 0.7126792023579279,\n",
       " 0.7230426708857218,\n",
       " 0.71598315,\n",
       " 0.6993898327151934,\n",
       " 0.6849393745263418,\n",
       " 0.70033383,\n",
       " 0.6367387591846405,\n",
       " 0.24873225,\n",
       " 0.7131726074786413,\n",
       " 0.72583985,\n",
       " 0.69035286,\n",
       " 0.7361317873001099,\n",
       " 0.6432618,\n",
       " 0.7627253598637052,\n",
       " 0.588441,\n",
       " 0.6476535714334912]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quickPrint(df, ans_col, eval_col, 3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(df, ans_col, eval_col, 3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(df, ans_col, eval_col, 3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(df, ans_col, eval_col, 3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(df, ans_col, eval_col, 2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(df, ans_col, eval_col, 2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(df, ans_col, eval_col, 2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(df, ans_col, eval_col, 1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(df, ans_col, eval_col, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(df, ans_col, eval_col, 0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construccion de CSV final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_csv(df, ans_col, eval_col):\n",
    "    tres_tres = quickPrint(df, ans_col, eval_col, 3,3)\n",
    "    tres_dos  = quickPrint(df, ans_col, eval_col, 3,2)\n",
    "    tres_uno  = quickPrint(df, ans_col, eval_col, 3,1)\n",
    "    tres_cero = quickPrint(df, ans_col, eval_col, 3,0)\n",
    "    dos_dos   = quickPrint(df, ans_col, eval_col, 2,2)\n",
    "    dos_uno   = quickPrint(df, ans_col, eval_col, 2,1)\n",
    "    dos_cero  = quickPrint(df, ans_col, eval_col, 2,0)\n",
    "    uno_uno   = quickPrint(df, ans_col, eval_col, 1,1)\n",
    "    uno_cero  = quickPrint(df, ans_col, eval_col, 1,0)\n",
    "    cero_cero = quickPrint(df, ans_col, eval_col, 0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construccion de CSV\n",
    "\n",
    "# df = pd.read_csv(\"C:/Users/Drablaguna/Desktop/UNAM/EvaluacionCognitiva/Bases de datos/Secundaria/SECUNDARIA_TODO.csv\")\n",
    "# ans_col = \"explica_lo_que_quiere_decir_mi_hermanito_es_una_pelota_de_gritos\"\n",
    "# eval_col = \"a5\"\n",
    "\n",
    "construct_csv(df, ans_col, eval_col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
