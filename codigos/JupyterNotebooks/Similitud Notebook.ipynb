{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similitud Notebook\n",
    "En este notebook podremos analizar con más facilidad la similitud entre las respuestas calificadas con mayor calificación con las de menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importo librerias\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hunspell import Hunspell\n",
    "\n",
    "h = Hunspell('es_MX', hunspell_data_dir = 'C:/Python/Lib/site-packages/dictionaries')\n",
    "spa_lex = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con esto evito que se impriman 'errores'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pprint import pprint\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciar modelo Gensim\n",
    "Cristian Cardellino: Spanish Billion Words Corpus and Embeddings (March 2016), https://crscardellino.github.io/SBWCE/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(\"C:/Users/Drablaguna/Desktop/UNAM/SBW-vectors-300-min5.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalChar(x):\n",
    "    if x in [\",\",\".\",\":\",\";\",\"`\",\"'\",'\"',\"(\",\")\",\"-\",\"_\",\"~\",\"/\",\"?\",\"¿\",\"=\",\"[\",\"]\",\"\\n\",\"\\r\"]:\n",
    "        x = \"\"\n",
    "    return x\n",
    "def cleanString(x):\n",
    "    \"\"\"eliminar caracteres de puntuacion\"\"\"\n",
    "    s = map(evalChar, x)\n",
    "    s = \"\".join(list(s))\n",
    "    return s\n",
    "\n",
    "def start_dict():\n",
    "    \"\"\"inicializar el diccionario de resultados, para tener resultados diferentes por prueba\"\"\"\n",
    "    dic = {\n",
    "    'token_base': [],      # tokens originales\n",
    "    'token_toCompare': [], # token con el que se comparo\n",
    "    'similarity': [],      # valor de la similitud de ambos\n",
    "    'total_sim_mean': 0    # promedio similitud por frase\n",
    "    }\n",
    "    return dic\n",
    "\n",
    "def checkWord(word, hun_dic, original_sentence):\n",
    "    \"\"\"elegir la palabra correcta entre sus sugerencias\"\"\"\n",
    "    if not hun_dic.spell(word): # si la palabra NO se encuentra en el diccionario hunspell\n",
    "        n = 0\n",
    "        a = hun_dic.suggest(word)\n",
    "        print(\"=> \" + original_sentence)\n",
    "        for x in a:\n",
    "            print(str(n) + \": \" + x)\n",
    "            n+=1\n",
    "        # se puede ingresar la respuesta correcta con el id o escribiendola manualmente\n",
    "        correct_id_word = input(\"(\"+word+\") ID respuesta correcta o ingresa la palabra: \")\n",
    "        if correct_id_word.isdigit():\n",
    "            correct = a[int(correct_id_word)]\n",
    "        else:\n",
    "            correct = correct_id_word\n",
    "    else: # si la palabra se encuentra en el diccionario hunspell\n",
    "        correct = word\n",
    "    return correct.strip().lower()\n",
    "\n",
    "def checkSentence(s_string, hun_dic):\n",
    "    \"\"\"checar una oracion usando la funcion de escoger la palabra correcta\"\"\"\n",
    "    new_sentence = []\n",
    "    for token in s_string.split(\" \"): # se evaluara cada token si es una palabra existente o no\n",
    "        correct_word = checkWord(token, hun_dic, s_string)\n",
    "        if correct_word != \"\": # se agregara a la oracion nueva solo si es algo\n",
    "            new_sentence.append(correct_word)\n",
    "    #print(\"\\n\")\n",
    "    return \" \".join(new_sentence)\n",
    "        \n",
    "# s = \"porque sii mas que nada\"\n",
    "# s = checkSentence(s,h)\n",
    "# print(s)\n",
    "\n",
    "def print_graded_subsets(df_base, head):\n",
    "    \"\"\"Imprimir las dimensiones de los 4 subsets de una columna, de acuerdo a su evaluacion\"\"\"\n",
    "    df_three = df_base.loc[df_base[eval_col] == 3]\n",
    "    df_two   = df_base.loc[df_base[eval_col] == 2]\n",
    "    df_one   = df_base.loc[df_base[eval_col] == 1]\n",
    "    df_zero  = df_base.loc[df_base[eval_col] == 0]\n",
    "    print(\" === 3 === \")\n",
    "    print(df_three.head(head))\n",
    "    print(df_three.shape)\n",
    "    print(\"\\n\")\n",
    "    print(\" === 2 === \")\n",
    "    print(df_two.head(head))\n",
    "    print(df_two.shape)\n",
    "    print(\"\\n\")\n",
    "    print(\" === 1 === \")\n",
    "    print(df_one.head(head))\n",
    "    print(df_one.shape)\n",
    "    print(\"\\n\")\n",
    "    print(\" === 0 === \")\n",
    "    print(df_zero.head(head))\n",
    "    print(df_zero.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analize(base, comparer, method):\n",
    "    dic = start_dict()\n",
    "    \n",
    "    if method == \"gensim\":\n",
    "        base = base.split(\" \")\n",
    "        comparer = comparer.split(\" \")\n",
    "        \n",
    "    for token_base in base:\n",
    "        for token_toCompare in comparer:\n",
    "            \n",
    "            if method == \"spacy\":\n",
    "                simil = token_base.similarity(token_toCompare)\n",
    "                dic['token_base'].append(token_base.text)\n",
    "                dic['token_toCompare'].append(token_toCompare.text)\n",
    "                dic['similarity'].append(simil)\n",
    "            \n",
    "            if method == \"gensim\":\n",
    "                try:\n",
    "                    simil = model.wv.similarity(w1=token_base, w2=token_toCompare)\n",
    "                except KeyError:\n",
    "                    print(f\"---> Alguna de las siguientes palabras: ['{token_base}', '{token_toCompare}'] , no fue encontrada.\")\n",
    "                    simil = 0\n",
    "                dic['token_base'].append(token_base)\n",
    "                dic['token_toCompare'].append(token_toCompare)\n",
    "                dic['similarity'].append(simil)\n",
    "                \n",
    "    # genero el promedio de similitud que fue extraido de la sim de cada token con token\n",
    "    dic['total_sim_mean'] = np.mean(dic['similarity'])\n",
    "    return dic\n",
    "\n",
    "def quickize(master_row, slave_row, spell_check, method):\n",
    "    \"\"\"analizar rapido y mostrar similitud\"\"\"\n",
    "    \n",
    "    \"\"\" ========== H U N S P E L L ========== \"\"\"\n",
    "    if spell_check == True:\n",
    "        master_row = checkSentence(master_row,h)\n",
    "        slave_row = checkSentence(slave_row,h)\n",
    "\n",
    "    \"\"\" ============= S P A C Y ============= \"\"\"\n",
    "    if method == \"spacy\":\n",
    "        master_row = spa_lex(master_row)\n",
    "        slave_row = spa_lex(slave_row)\n",
    "        dic = analize(master_row, slave_row, method)\n",
    "    else:\n",
    "        \"\"\" ========== G E N S I M ========== \"\"\"\n",
    "        dic = analize(master_row, slave_row, method)\n",
    "    \n",
    "    return dic\n",
    "\n",
    "def print_zip(dic):\n",
    "    \"\"\"imprimir las palabras que se compararon y sus similitudes\"\"\"\n",
    "    print(list(zip(dic['token_base'], dic['token_toCompare'], dic['similarity'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Drablaguna/Desktop/UNAM/EvaluacionCognitiva/Bases de datos/Secundaria/SECUNDARIA_TODO.csv\", encoding='latin1')\n",
    "\n",
    "# df = pd.read_csv(\"C:/Users/Drablaguna/Desktop/UNAM/EvaluacionCognitiva/cuenta_de_palabras/WORDCOUNT_SECUNDARIA.csv\")\n",
    "\n",
    "df_base = df[[ans_col, eval_col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes evaluados a  3, 2, 1 y 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_graded_subsets(df_base, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_df_res(master_row, df_slave, ans_col):\n",
    "    \"\"\"evaluar 1 respuesta de 3 con master rows definidas\"\"\"\n",
    "    counter = 1\n",
    "    results = []\n",
    "    master_row = cleanString(master_row)\n",
    "    #print(\"============================== \"+master_row.upper()+\" ==============================\")\n",
    "    for line in df_slave[ans_col]:\n",
    "        slave_row = cleanString(line)\n",
    "        if slave_row != \"\": # para evitar evaluaciones donde la fila este vacia\n",
    "            r = quickize(master_row, slave_row, False, \"spacy\")\n",
    "            results.append(r['total_sim_mean'])\n",
    "            # print(str(r['total_sim_mean'])) # SIMILITUD POR ORACION\n",
    "            counter+=1\n",
    "    return results\n",
    "\n",
    "def quickPrint(master_row, df, ans_col, eval_col, n1, n2):\n",
    "    df_base  = df[[ans_col, eval_col]]\n",
    "    final_results = []\n",
    "    \n",
    "    df_three = df_base.loc[df_base[eval_col] == 3]\n",
    "    df_two   = df_base.loc[df_base[eval_col] == 2]\n",
    "    df_one   = df_base.loc[df_base[eval_col] == 1]\n",
    "    df_zero  = df_base.loc[df_base[eval_col] == 0]\n",
    "\n",
    "    \n",
    "    # 3 con 3\n",
    "    if n1 == 3 and n2 == 3:\n",
    "        final_results = print_df_res(master_row, df_three, ans_col)\n",
    "        \n",
    "    # 3 con 2\n",
    "    if n1 == 3 and n2 == 2:\n",
    "        final_results = print_df_res(master_row, df_two, ans_col)\n",
    "        \n",
    "    # 3 con 1\n",
    "    if n1 == 3 and n2 == 1:\n",
    "        final_results = print_df_res(master_row, df_one, ans_col)\n",
    "        \n",
    "    # 3 con 0\n",
    "    if n1 == 3 and n2 == 0:\n",
    "        final_results = print_df_res(master_row, df_zero, ans_col)\n",
    "    \n",
    "    \n",
    "    # 2 con 2\n",
    "    if n1 == 2 and n2 == 2:\n",
    "        final_results = print_df_res(master_row, df_two, ans_col)\n",
    "        \n",
    "    # 2 con 1\n",
    "    if n1 == 2 and n2 == 1:\n",
    "        final_results = print_df_res(master_row, df_one, ans_col)\n",
    "        \n",
    "    # 2 con 0\n",
    "    if n1 == 2 and n2 == 0:\n",
    "        final_results = print_df_res(master_row, df_zero, ans_col)\n",
    "        \n",
    "    \n",
    "    # 1 con 1\n",
    "    if n1 == 1 and n2 == 1:\n",
    "        final_results = print_df_res(master_row, df_one, ans_col)\n",
    "        \n",
    "    # 1 con 0\n",
    "    if n1 == 1 and n2 == 0:\n",
    "        final_results = print_df_res(master_row, df_zero, ans_col)\n",
    "        \n",
    "    \n",
    "    # 0 con 0\n",
    "    if n1 == 0 and n2 == 0:\n",
    "        final_results = print_df_res(master_row, df_zero, ans_col)\n",
    "        \n",
    "    \n",
    "    # Imprimir resultados\n",
    "    # pprint(list(enumerate(final_results, 1)))\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ======================= M A S T E R  R O W S ======================= \"\"\"\n",
    "    \n",
    "master_rows = [\n",
    "    \"por que hace mucho ruido\",\n",
    "    \"porque grita mucho\"\n",
    "    ]\n",
    "    \n",
    "\"\"\" ==================================================================== \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(master_row, df, ans_col, eval_col, 3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(master_row, df, ans_col, eval_col, 3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(master_row, df, ans_col, eval_col, 3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(master_row, df, ans_col, eval_col, 3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(master_row, df, ans_col, eval_col, 2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(master_row, df, ans_col, eval_col, 2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(master_row, df, ans_col, eval_col, 2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(master_row, df, ans_col, eval_col, 1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(master_row, df, ans_col, eval_col, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickPrint(master_row, df, ans_col, eval_col, 0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construccion de CSV final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataframe(master_row, df, ans_col, eval_col, stopwords):\n",
    "    master_name = master_row.replace(\" \", \"_\")\n",
    "\n",
    "    tres_tres = quickPrint(master_row, df, ans_col, eval_col, 3,3)\n",
    "    tres_dos  = quickPrint(master_row, df, ans_col, eval_col, 3,2)\n",
    "    tres_uno  = quickPrint(master_row, df, ans_col, eval_col, 3,1)\n",
    "    tres_cero = quickPrint(master_row, df, ans_col, eval_col, 3,0)\n",
    "    \n",
    "    dos_dos   = quickPrint(master_row, df, ans_col, eval_col, 2,2)\n",
    "    dos_uno   = quickPrint(master_row, df, ans_col, eval_col, 2,1)\n",
    "    dos_cero  = quickPrint(master_row, df, ans_col, eval_col, 2,0)\n",
    "    \n",
    "    uno_uno   = quickPrint(master_row, df, ans_col, eval_col, 1,1)\n",
    "    uno_cero  = quickPrint(master_row, df, ans_col, eval_col, 1,0)\n",
    "    \n",
    "    cero_cero = quickPrint(master_row, df, ans_col, eval_col, 0,0)\n",
    "    \n",
    "    # Longitudes de arreglos\n",
    "    l3_3 = [\"3_3\" for x in tres_tres]\n",
    "    l3_2 = [\"3_2\" for x in tres_dos]\n",
    "    l3_1 = [\"3_1\" for x in tres_uno]\n",
    "    l3_0 = [\"3_0\" for x in tres_cero]\n",
    "    \n",
    "    l2_2 = [\"2_2\" for x in dos_dos]\n",
    "    l2_1 = [\"2_1\" for x in dos_uno]\n",
    "    l2_0 = [\"2_0\" for x in dos_cero]\n",
    "    \n",
    "    l1_1 = [\"1_1\" for x in uno_uno]\n",
    "    l1_0 = [\"1_0\" for x in uno_cero]\n",
    "    \n",
    "    l0_0 = [\"0_0\" for x in cero_cero]\n",
    "    \n",
    "    indexes_3 = l3_3 + l3_2 + l3_1 + l3_0\n",
    "    indexes_2 = l2_2 + l2_1 + l2_0\n",
    "    indexes_1 = l1_1 + l1_0\n",
    "    \n",
    "    values_3 = tres_tres + tres_dos + tres_uno + tres_cero\n",
    "    values_2 = dos_dos + dos_uno + dos_cero\n",
    "    values_1 = uno_uno + uno_cero\n",
    "\n",
    "    if stopwords == True: # SI LA SIMILITUD ES CON STOPWORDS\n",
    "        dic = {\n",
    "            \"id_3_\"+master_name:    pd.Series(indexes_3),\n",
    "            \"eval_3_\"+master_name:  pd.Series(values_3),\n",
    "            \"id_2_\"+master_name:    pd.Series(indexes_2),\n",
    "            \"eval_2_\"+master_name:  pd.Series(values_2),\n",
    "            \"id_1_\"+master_name:    pd.Series(indexes_1),\n",
    "            \"eval_1_\"+master_name:  pd.Series(values_1),\n",
    "            \"id_0_\"+master_name:    pd.Series(l0_0),\n",
    "            \"eval_0_\"+master_name:  pd.Series(cero_cero)\n",
    "        }\n",
    "\n",
    "        res_df = pd.DataFrame(dic, columns=[\n",
    "            \"id_3_\"+master_name,\n",
    "            \"eval_3_\"+master_name,\n",
    "            \"id_2_\"+master_name,\n",
    "            \"eval_2_\"+master_name,\n",
    "            \"id_1_\"+master_name,\n",
    "            \"eval_1_\"+master_name,\n",
    "            \"id_0_\"+master_name,\n",
    "            \"eval_0_\"+master_name\n",
    "        ])\n",
    "    else: # SI LA SIMILITUD ES SIN STOPWORDS\n",
    "        dic = {\n",
    "            \"noStop_id_3_\"+master_name:    pd.Series(indexes_3),\n",
    "            \"noStop_eval_3_\"+master_name:  pd.Series(values_3),\n",
    "            \"noStop_id_2_\"+master_name:    pd.Series(indexes_2),\n",
    "            \"noStop_eval_2_\"+master_name:  pd.Series(values_2),\n",
    "            \"noStop_id_1_\"+master_name:    pd.Series(indexes_1),\n",
    "            \"noStop_eval_1_\"+master_name:  pd.Series(values_1),\n",
    "            \"noStop_id_0_\"+master_name:    pd.Series(l0_0),\n",
    "            \"noStop_eval_0_\"+master_name:  pd.Series(cero_cero)\n",
    "        }\n",
    "\n",
    "        res_df = pd.DataFrame(dic, columns=[\n",
    "            \"noStop_id_3_\"+master_name,\n",
    "            \"noStop_eval_3_\"+master_name,\n",
    "            \"noStop_id_2_\"+master_name,\n",
    "            \"noStop_eval_2_\"+master_name,\n",
    "            \"noStop_id_1_\"+master_name,\n",
    "            \"noStop_eval_1_\"+master_name,\n",
    "            \"noStop_id_0_\"+master_name,\n",
    "            \"noStop_eval_0_\"+master_name\n",
    "        ])\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de similitud todas las master rows **CON STOPWORDS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construccion de CSV | visualizar con -> display(stop[x])\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "# PALABRAS CORREGIDAS SECUNDARIA ================================================================\n",
    "df = pd.read_csv(\"C:/Users/Drablaguna/Desktop/UNAM/EvaluacionCognitiva/Bases de datos/Secundaria/palabras_corregidas_secundaria.csv\", encoding='latin1')\n",
    "ans_col = \"clean_explica_lo_que_quiere_decir_mi_hermanito_es_una_pelota_de_gritos\"\n",
    "eval_col = \"a5\"\n",
    "\n",
    "for master in master_rows:\n",
    "    dataframes.append(construct_dataframe(master, df, ans_col, eval_col, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de similitud todas las master rows **SIN STOPWORDS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORDCOUNT SECUNDARIA ===========================================================\n",
    "df = pd.read_csv(\"C:/Users/Drablaguna/Desktop/UNAM/EvaluacionCognitiva/cuenta_de_palabras/WORDCOUNT_SECUNDARIA.csv\", encoding='latin1')\n",
    "ans_col = \"explica_lo_que_quiere_decir_mi_hermanito_es_una_pelota_de_gritos_clean_ans\"\n",
    "eval_col = \"explica_lo_que_quiere_decir_mi_hermanito_es_una_pelota_de_gritos_eval\"\n",
    "\n",
    "for master in master_rows:\n",
    "    dataframes.append(construct_dataframe(master, df, ans_col, eval_col, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenar todos los dataframes y generar el CSV final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(dataframes, axis=1)\n",
    "final_df.to_csv(\"C:/Users/Drablaguna/Desktop/Resultados_Gensim.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
